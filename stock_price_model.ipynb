{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38258eb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/Saudii/AppData/Local/Programs/Python/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorfloiw .keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf49907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"refined_data.csv\")\n",
    "df = pd.read_csv(\"stock_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c900a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '_' with NaN in numeric columns, then conert to float\n",
    "for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Closed\", \"Volume\"]:\n",
    "    df2[col] = df2[col].replace('_', np.nan) # Replace with NaN\n",
    "    df2[col] = df2[col].replace(',', '', regex=True) # Remove commas\n",
    "    df2[col] = df2[col].astype(float) # Convert to float\n",
    "\n",
    "# Handle missing values (forward fill)\n",
    "df2.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date columns to datetime (handles mixed formats automatically)\n",
    "df1['Date'] = pd.to_datetime(df1['Date'], format='mixed') \n",
    "df2['Date'] = pd.to_datetime(df2['Date'], format='mixed')\n",
    "\n",
    "# Merge datesets on Date\n",
    "df = pd.merge(df1, df2, on='Date', how='inner')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handles Missing Values\n",
    "df = df.fillna(method='ffill') # Forward fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ebcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable (Uptrend = 1, Downtrend = 0)\n",
    "df['Target'] = (df['Close_y'].shift(-1) > df['Close_y']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19555a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting new features \n",
    "features = [col for col in df.columns if col not in ['Date', 'Targt']]\n",
    "x = df[features].values\n",
    "y = df['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba19f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee497bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM expects 3D input (samples, timesteps, features)\n",
    "timesteps = 10\n",
    "def create_sequences(X, y, timesteps):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - timesteps):\n",
    "        Xs.append(X[i:i+timesteps])\n",
    "        ys.append(y[i+timesteps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5aa473",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, timesteps)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]), return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8850d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss= 'binary_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm_model.fit(X_train_seq, y_train_seq, epochs=40, batch_size=32,\n",
    "                         validation_data=(X_test_seq, y_test_seq), verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd8ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with LSTM\n",
    "y_pred_lstm = (lstm_model.predict(X_test_seq) > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ccc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gradient Boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "xgb = XGBoostClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble prediction (majority voting)\n",
    "final_preds = []\n",
    "for i in range(len(y_test)):\n",
    "    votes = [y_pred_lstm[i % len(y_pred_lstm)], y_pred_rf[i], y_pred_gb[i], y_pred_xgb[i]]\n",
    "    final_preds.append(int(sum(votes) >= 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models\n",
    "def evaluate_model(y_true, y_pred, name):\n",
    "    rms = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"{name} -> RMSE: {rms:.4f}, \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
